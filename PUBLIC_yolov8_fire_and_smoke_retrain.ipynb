{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naimaryan1/Smoke_Fire_Detection_On_Edge_Devices/blob/main/PUBLIC_yolov8_fire_and_smoke_retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complete training pipeline to train YOLOv8 classifier for fire & smoke detection based on images.**\n",
        "\n",
        "\n",
        "**Motivation:** In recent years, early fire detection has become vital due to large-scale fires causing extensive financial damage and loss of life in such places as the United States, Canada, and Europe. This intercative coding environment introduces how to train deep neural networks for detecting fire and smoke, leveraging the inference of high-speed YOLO architecture. YOLO can be optimized for deployment on resource-limited edge hardware like the Raspberry Pi. The tutorial covers the entire process, including data preprocessing, model training, hyperparameter tuning, evaluating model metrics, and conducting model inference in a cloud environment.\n",
        "\n",
        "**Step 1:**\n",
        "\n",
        "Since we are going to run long running tasks we need a way to keep Google Collab alive even after hours of running. Even if you sign for Google Collab’s “professional” version the browser will timeout after ~30 min of inactivity.\n",
        "\n",
        "Do this hack to keep your browser alive:\n",
        "https://www.codeease.net/programming/javascript/keep-colab-from-disconnecting\n",
        "\n"
      ],
      "metadata": {
        "id": "Vpacif2lqiXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Complete training pipeline to train YOLOv8 classifier for fire & smoke detecction based on images.\n",
        "\n",
        "Developer: Ary Naim (anaim@unm.edu)\n",
        "\n",
        "Advisor: Dr. Marios Pattichis (pattichi@unm.edu)\n",
        "\n",
        "Github:\n",
        "\n",
        "References:\n",
        "\n",
        "1) Implementation was heavily based on:                         https://keras.io/examples/vision/yolov8/\n",
        "2) Adding custom dataset via tensorflow:                        https://www.tensorflow.org/datasets/add_dataset\n",
        "3) Dataset->                                                    https://github.com/gaiasd/DFireDataset\n",
        "4) Attemptiong to reproduce this paper however using YOLOv8:\n",
        "                                                                https://link.springer.com/article/10.1007/s00521-023-08260-2\n",
        "                                                                https://www.researchgate.net/publication/361649776_An_automatic_fire_detection_system_based_on_deep_convolutional_neural_networks_for_low-power_resource-constrained_devices#fullTextFileContent\n",
        "\n",
        "\n",
        "Status: Since YOLOv8 is relatively new & there are ongoing issues & improvments this is a live document.\n",
        "\n",
        "Known Issues related Keras's implementation of YOLOv8:\n",
        "1) https://github.com/keras-team/keras-cv/issues/2095\n",
        "2) https://github.com/keras-team/keras-cv/issues/2442\n",
        "3) KERAS YOLOv8 DOEST traditional metrics: https://github.com/keras-team/keras/issues/19416\n",
        "\n",
        "WARNING: After running the experiment or any development change the runtime to CPU or \"Disconnect & delete runtime\" or\n",
        "you will be charged pet hour by Google.\n",
        "\n",
        "WARNING: No Warranties. The author makes no warranties, express or implied, with respect to code. Use at your own risk.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#PLEASE READ & EXECUTE STEP BY STEP.\n",
        "\"\"\" STEP 1) To avoid reconnects read: https://www.codeease.net/programming/javascript/keep-colab-from-disconnecting\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" Step 2) Installation steps\"\"\"\n",
        "#installations - START\n",
        "!pip install tensorflow==2.15.0  # Upgrade to TensorFlow 2.  # Remove Keras 2.\n",
        "!pip install keras==2.15.0  # Upgrade to Keras 2.\n",
        "!pip install keras-cv\n",
        "!pip install h5py\n",
        "!pip install matplotlib\n",
        "#installations - END"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfEBS8fgrYIT",
        "outputId": "b0c2c373-c1e5-4ab1-d3fd-9689d66f9540"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Requirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv) (4.9.4)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-cv) (0.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras-cv)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.5.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (4.11.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras-cv\n",
            "Successfully installed keras-core-0.1.7 keras-cv-0.9.0 namex-0.0.8\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5lO6MbZrn9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount your Google Drive**\n"
      ],
      "metadata": {
        "id": "gFT0QlJqrzhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Step 3) Mount Drive\"\"\"\n",
        "#MOUNT DRIVE - START\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#link your path to create a symbolic link\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "#MOUNT DRIVE - END\n"
      ],
      "metadata": {
        "id": "hnRZHXV8sBUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9fe61e5-3dce-4c2d-f7ce-16429bc7e325"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "ln: failed to create symbolic link '/mydrive/My Drive': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 4: Import the required libraries***"
      ],
      "metadata": {
        "id": "F1TeGkvmsP5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Step 4) Mount imports\"\"\"\n",
        "#imports - START\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "sys.path.append('..')\n",
        "sys.path.append('/content/gdrive/MyDrive/my_fire_smoke_dataset') #You & can should have this to refer to the location for your custom dataset\n",
        "#import custom dataset\n",
        "from my_fire_smoke_dataset import MyFireSmokeDataset\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "from tensorflow import data as tf_data\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "print(\"TF VERSION:\",tf.__version__)\n",
        "import keras\n",
        "print(\"Keras VERSION:\",keras.__version__)\n",
        "import keras_cv\n",
        "import numpy as np\n",
        "from keras_cv import bounding_box\n",
        "from keras_cv import visualization\n",
        "import tqdm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "keras.backend.clear_session()\n",
        "keras.backend.set_floatx(\"float32\")\n",
        "#imports - END"
      ],
      "metadata": {
        "id": "0-sv6RFdsRWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc679a9-43ea-4539-cdd2-16dba017cf35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF VERSION: 2.15.0\n",
            "Keras VERSION: 2.15.0\n",
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optional - Step 5) Add dataset to Keras**\n",
        "\n",
        "**IMPORTANT:**\n",
        "\n",
        "**If** you are using a precanned dataset from Keras OR you just want to run this Notbobook as is, you can skip this step #5 & go to step 6.\n",
        "\n",
        "**Else** if you have custom dataset you have to follow this guide (https://www.tensorflow.org/datasets/add_dataset) along with our detailed instructions in the Word doc titled \"Guide\"\n",
        "\n",
        "*   Before proceeding and makesure the command \"tfds build --register_checksums\" returns no errors."
      ],
      "metadata": {
        "id": "TkjsL1uOsvZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 6) Declare variables & functions**"
      ],
      "metadata": {
        "id": "AZL0RXJ_tqXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"step 6) declare variables & functions\"\"\"\n",
        "\n",
        "#VARIABLES.\n",
        "#IMPORTANT: change the labels here to reflect the actual labels you have based on your dataset.\n",
        "class_ids = [\n",
        "    \"Fire\",\n",
        "     \"Smoke\",\n",
        "]\n",
        "\n",
        "image_size_1 = (640,640) #we are only using this tuple image_size_1. The YOLO sizes must be multiples of 32.\n",
        "image_size_2 = (320,320)\n",
        "image_size_3 = (160,160)\n",
        "\n",
        "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
        "\n",
        "\n",
        "# FUNCTION DECLARATIONS - START\n",
        "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
        "    inputs = next(iter(inputs.take(1)))\n",
        "    #inputs = inputs[1]\n",
        "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=value_range,\n",
        "        rows=rows,\n",
        "        cols=cols,\n",
        "        y_true=None,\n",
        "        scale=5,\n",
        "        font_scale=0.7,\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        class_mapping=class_mapping,\n",
        "    )\n",
        "\n",
        "\n",
        "def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n",
        "    image = inputs[\"image\"]\n",
        "    boxes = keras_cv.bounding_box.convert_format(\n",
        "        inputs[\"objects\"][\"bbox\"],\n",
        "        images=image,\n",
        "        source=\"rel_yxyx\",\n",
        "        target=bounding_box_format,\n",
        "    )\n",
        "    bounding_boxes = {\n",
        "        \"classes\": inputs[\"objects\"][\"label\"],\n",
        "        \"boxes\": boxes,\n",
        "    }\n",
        "    return {\"images\": image, \"bounding_boxes\": bounding_boxes}\n",
        "\n",
        "\n",
        "def load_pascal_voc(split, dataset, bounding_box_format):\n",
        "    ds = tfds.load(dataset, split=split, with_info=False, shuffle_files=True)\n",
        "    ds = ds.map(\n",
        "        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n",
        "        num_parallel_calls=tf_data.AUTOTUNE,\n",
        "    )\n",
        "    return ds\n",
        "\n",
        "#Example of getting precanned data. This is good for learning.\n",
        "def get_data_train_ds():\n",
        "  train_ds = load_pascal_voc(split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xyxy\")\n",
        "  return train_ds\n",
        "\n",
        "#Example of getting precanned data. This is good for learning.\n",
        "def get_data_eval_ds():\n",
        "  eval_ds = load_pascal_voc(split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xyxy\")\n",
        "  return eval_ds\n",
        "\n",
        "#Example of getting custom data. Refer to:https://www.tensorflow.org/datasets/add_datase\n",
        "def get_data_train_ds_my_fire_smoke():\n",
        "  train_ds = load_pascal_voc(split=\"train\", dataset=\"my_fire_smoke_dataset\", bounding_box_format=\"xyxy\")\n",
        "  return train_ds\n",
        "\n",
        "#Example of getting custom data. Refer to: https://www.tensorflow.org/datasets/add_datase\n",
        "def get_data_eval_ds_my_fire_smoke():\n",
        "  eval_ds = load_pascal_voc(split=\"test\", dataset=\"my_fire_smoke_dataset\", bounding_box_format=\"xyxy\")\n",
        "  return eval_ds\n",
        "\n",
        "def create_augmenter_fn(augmenters):\n",
        "    def augmenter_fn(inputs):\n",
        "        for augmenter in augmenters:\n",
        "            inputs = augmenter(inputs)\n",
        "        return inputs\n",
        "    return augmenter_fn\n",
        "#Data augmentation - END\n",
        "\n",
        "def dict_to_tuple(inputs):\n",
        "    return inputs[\"images\"], bounding_box.to_dense(\n",
        "        inputs[\"bounding_boxes\"], max_boxes=32\n",
        "    )\n",
        "\n",
        "\n",
        "def visualize_predictions(images, y_true, y_pred, bounding_box_format):\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=(0, 255),\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        scale=4,\n",
        "        rows=2,\n",
        "        cols=2,\n",
        "        show=True,\n",
        "        font_scale=0.7,\n",
        "        class_mapping=class_mapping,\n",
        "    )\n",
        "\n",
        "def visualize_detections(model, dataset, bounding_box_format):\n",
        "    images, y_true = next(iter(dataset.take(1)))\n",
        "    y_pred = model.predict(images)\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=(0, 255),\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        scale=4,\n",
        "        rows=2,\n",
        "        cols=2,\n",
        "        show=True,\n",
        "        font_scale=0.7,\n",
        "        class_mapping=class_mapping,\n",
        "    )\n",
        "\n",
        "#load data\n",
        "def load_images_from_folder(folder):\n",
        "  print(\"load_images_from_folder - START...\")\n",
        "  counter_images=0\n",
        "  images = []\n",
        "  for filename in os.listdir(folder):\n",
        "    counter_images=counter_images+1\n",
        "    print(\"counter_images\",counter_images)\n",
        "    img = Image.open(os.path.join(folder, filename))\n",
        "    if img is not None:\n",
        "      images.append(img)\n",
        "  print(\"load_images_from_folder - END\")\n",
        "  return images\n",
        "\n",
        "def load_labels_from_folder(folder):\n",
        "    print(\"load_images_from_folder - START...\")\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "          with open(os.path.join(folder, filename), 'r') as file:\n",
        "            first_line = file.readline()\n",
        "            if len(first_line.strip())!=0:\n",
        "                label = first_line.strip().split(\" \")\n",
        "                labels.append(label)\n",
        "            else:\n",
        "                labels.append([0,0,0,0,0])\n",
        "    print(\"load_images_from_folder - END...\")\n",
        "    return labels\n",
        "\n",
        "def resize_image(image, size):\n",
        "    return image.resize(size)\n",
        "\n",
        "def convert_to_yolo_format(label, image_size):\n",
        "    yolo_labels = []\n",
        "    class_id = 0\n",
        "    if len(label)!=0 and len(image_size)!=0:\n",
        "        if label[0]!=0:\n",
        "            image_width = float(image_size[0])\n",
        "            image_height = float(image_size[1])\n",
        "            if image_width and image_height and float(label[1]) <= image_width and  float(label[2]) <= image_height:\n",
        "                class_id = int(label[0])  # Assuming the class label is the first element\n",
        "                x1 = float(label[1])\n",
        "                y1 = float(label[2])\n",
        "                w = float(label[3])\n",
        "                h = float(label[4])\n",
        "                #YOLO normalises the image space to run from 0 to 1 in both x and y directions\n",
        "                x1 = x1 / image_width\n",
        "                y1 = y1 = image_height\n",
        "                w = w / image_width\n",
        "                h = h / image_height\n",
        "                #add class & bounding box\n",
        "                yolo_label = [class_id, x1, y1,w,h]\n",
        "                yolo_labels.append(yolo_label)\n",
        "        else:\n",
        "            #TODO are we coming here\n",
        "            yolo_labels.append(label)\n",
        "    return yolo_labels\n",
        "\n",
        "def process_dataset(image_folder, label_folder, image_size):\n",
        "    print(\"process_dataset - START...\")\n",
        "    images = load_images_from_folder(image_folder)\n",
        "    labels = load_labels_from_folder(label_folder)\n",
        "    resized_images = []\n",
        "    counter_images=0\n",
        "    for img in images:\n",
        "        resized_images.append(resize_image(img, image_size))\n",
        "        counter_images=counter_images+1\n",
        "        print(\"counter_images\",counter_images)\n",
        "    yolo_labels = []\n",
        "    counter_labels=0\n",
        "    for lbl in labels:\n",
        "        yolo_labels.append(convert_to_yolo_format(lbl, image_size))\n",
        "        counter_labels=counter_labels+1\n",
        "        print(\"counter_labels\",counter_labels)\n",
        "    print(\"process_dataset - END\")\n",
        "    return resized_images, yolo_labels\n",
        "\n",
        "def get_jpeg_files(path):\n",
        "    jpeg_files = []\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
        "            jpeg_files.append(os.path.join(path, file))\n",
        "    return jpeg_files\n",
        "\n",
        "def get_txt_files(path):\n",
        "    txt_files = []\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".txt\"):\n",
        "          txt_files.append(os.path.join(path, file))\n",
        "    return txt_files\n",
        "\n",
        "def prepare_yolo_dataset(data_path, image_size):\n",
        "    print(\"prepare_yolo_dataset - START...\")\n",
        "    return process_dataset(os.path.join(data_path, 'images'), os.path.join(data_path, 'labels'),image_size)\n",
        "    print(\"prepare_yolo_dataset - END\")\n",
        "\n",
        "# Create a function to read the bounding boxes from a text file\n",
        "def read_bounding_boxes(label_file):\n",
        "  print(\"read_bounding_boxes - START\")\n",
        "  with open(label_file, 'r') as f:\n",
        "    bounding_boxes = []\n",
        "    for line in f:\n",
        "      if not line.strip():\n",
        "        # Empty line, set class to 0 and bounding box to 0,0,0,0\n",
        "        bounding_boxes.append({\n",
        "            'class': 0,\n",
        "            'x': 0.0,\n",
        "            'y': 0.0,\n",
        "            'width': 0.0,\n",
        "            'height': 0.0\n",
        "        })\n",
        "      else:\n",
        "        class_name, x, y, w, h = line.split()\n",
        "        bounding_boxes.append({\n",
        "            'class': class_name,\n",
        "            'x': float(x),\n",
        "            'y': float(y),\n",
        "            'width': float(w),\n",
        "            'height': float(h)\n",
        "        })\n",
        "  print(\"read_bounding_boxes - END\")\n",
        "  return bounding_boxes\n",
        "\n",
        "# Create a function to load an image and its corresponding bounding boxes\n",
        "def load_image_and_bounding_boxes(image_file, label_file):\n",
        "  print(\"load_image_and_bounding_boxes - START\")\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "  image = tf.image.resize(image,\n",
        "    size=image_size_1,\n",
        "    method='nearest',\n",
        "    preserve_aspect_ratio=False,\n",
        "    antialias=False,\n",
        "    name=None)\n",
        "  bounding_boxes = read_bounding_boxes(label_file)\n",
        "  print(\"load_image_and_bounding_boxes - END\")\n",
        "  return image, bounding_boxes\n",
        "\n",
        "\n",
        "def shuffle_generator(image, bounding,label, seed):\n",
        "    idx = np.arange(len(image))\n",
        "    np.random.default_rng(seed).shuffle(idx)\n",
        "    for i in idx:\n",
        "        yield image[i],bounding[i],label[i]\n",
        "# FUNCTION DECLARATIONS - END"
      ],
      "metadata": {
        "id": "lo-h3cA4trUQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 7) Start the experiment & load data**\n",
        "\n",
        "Noe that we have imported all the required imports and declared all the required functions. Lets run the experiment.\n",
        "\n",
        "**YOU NEED A RUNTIME WITH A GPU.** Makesure to switch the runtime to a GPU that you can afford (start with L4). You may need re-run previous steps as the runtime is restarted.\n",
        "\n",
        "You should start seeing the dataset being loaded. This will take a while even though we are only using 500 images which is not enough for building an accurate model.\n",
        "\n",
        "*Note:* If you want to load the entire 20,000 images open the Python file title “my_fire_smoke_dataset.py” and make an update in the function."
      ],
      "metadata": {
        "id": "XlIihUR-v2bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"step 7) Start the experiment & load data\"\"\"\n",
        "#PARAMATERS\n",
        "BATCH_SIZE = 4\n",
        "#hyperparameters - START\n",
        "#hyperparameters\n",
        "LEARNING_RATE = 0.005  #try 0.001 to 0.005\n",
        "EPOCHS = 50 # 50 is not enough, the original paper ran epoches frpm 5,000 to 30,000\n",
        "MOMENTUM = 0.9\n",
        "#hyperparameters - END\n",
        "\n",
        "#GET DATA\n",
        "print(\"GET DATA - START \")\n",
        "#original\n",
        "train_ds = get_data_train_ds_my_fire_smoke()\n",
        "eval_ds = get_data_eval_ds_my_fire_smoke()\n",
        "# #my_fire_smoke\n",
        "# train_ds = get_data_train_ds()\n",
        "# eval_ds = get_data_eval_ds()\n",
        "print(\"GET DATA - END\")\n",
        "\n",
        "#PREPROCESS - START\n",
        "print(\"#PREPROCESS - START\")\n",
        "# train_ds = train_ds.shuffle(BATCH_SIZE)\n",
        "# eval_ds = eval_ds.shuffle(BATCH_SIZE)\n",
        "\n",
        "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "eval_ds = eval_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "# #VISUALIZATION - optional\n",
        "visualize_dataset(train_ds, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2)\n",
        "visualize_dataset(\n",
        "      eval_ds,\n",
        "      bounding_box_format=\"xyxy\",\n",
        "      value_range=(0, 255),\n",
        "      rows=2,\n",
        "      cols=2,\n",
        "      # If you are not running your experiment on a local machine, you can also\n",
        "      # make `visualize_dataset()` dump the plot to a file using `path`:\n",
        "      # path=\"eval.png\"\n",
        "  )\n",
        "\n",
        "augmenters = [\n",
        "    keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
        "    keras_cv.layers.JitteredResize(\n",
        "        target_size=image_size_1, scale_factor=(0.75, 1.3), bounding_box_format=\"xyxy\"\n",
        "    ),\n",
        "]\n",
        "print(\"AUGMENTATION - START\")\n",
        "augmenter_fn = create_augmenter_fn(augmenters)\n",
        "train_ds = train_ds.map(augmenter_fn, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "visualize_dataset(\n",
        "    train_ds, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2\n",
        ")\n",
        "\n",
        "inference_resizing = keras_cv.layers.Resizing(\n",
        "   image_size_1[0],image_size_1[1], bounding_box_format=\"xyxy\", pad_to_aspect_ratio=True\n",
        ")\n",
        "print(\"RESIZING - START\")\n",
        "eval_ds = eval_ds.map(inference_resizing, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "visualize_dataset(\n",
        "    eval_ds, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2\n",
        ")\n",
        "#In order to be TPU compatible, bounding box Tensors need to be Dense instead of Ragged.\n",
        "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "eval_ds = eval_ds.map(dict_to_tuple, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
        "eval_ds = eval_ds.prefetch(tf_data.AUTOTUNE)\n",
        "#PREPROCESS - END\n",
        "\n",
        "#OPTIMIZER - START\n",
        "# including a global_clipnorm is extremely important in object detection tasks\n",
        "optimizer = keras.optimizers.SGD(\n",
        "    learning_rate=LEARNING_RATE, momentum=MOMENTUM, global_clipnorm=10.0\n",
        ")\n",
        "#OPTIMIZER - END\n",
        "\n",
        "\n",
        "#LOSS FUNCTION - START\n",
        "# The following NonMaxSuppression layer is equivalent to disabling the operation\n",
        "prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
        "    bounding_box_format=\"xyxy\",\n",
        "    from_logits=True,\n",
        "    iou_threshold=1.0,\n",
        "    confidence_threshold=0.0,\n",
        ")\n",
        "#LOSS FUNCTION - END\n",
        "\n",
        "#DEFINE MODEL\n",
        "#YOLOv8, references: https://keras.io/api/keras_cv/models/backbones/yolo_v8/\n",
        "#A medium YOLOV8 backbone pretrained on COCO\n",
        "model = keras_cv.models.YOLOV8Detector(\n",
        "    num_classes=len(class_ids),\n",
        "    bounding_box_format=\"xyxy\",\n",
        "    backbone=keras_cv.models.YOLOV8Backbone.from_preset(\n",
        "        \"yolo_v8_m_backbone_coco\"\n",
        "    ),\n",
        "    fpn_depth=2\n",
        ")\n",
        "\n",
        "#TRAINING - START\n",
        "#the KerasCV API to construct an untrained YOLOV8Detector model\n",
        "print(\"TRAINING - START\")\n",
        "\n",
        "model.compile(\n",
        "    classification_loss=\"binary_crossentropy\",\n",
        "    box_loss=\"ciou\",\n",
        "    optimizer=optimizer,\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#METRICS CALL BACK\n",
        "metrics_callback = keras_cv.callbacks.PyCOCOCallback(\n",
        "    eval_ds, bounding_box_format=\"xyxy\"\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    # Run for 10-35~ epochs to achieve good scores.\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[metrics_callback],\n",
        ")\n",
        "\n",
        "#Save the model to disk to avoid having to rebuild everytime you want to use the model\n",
        "model_path = F\"/content/gdrive/My Drive/ece551/week2_model/YOLOV8_model.keras\"\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691,
          "referenced_widgets": [
            "41b519065c7345558280f3fdfd32782c",
            "55d70f4294c144698fbedb58eb55f741",
            "786588327cce41bd8781e5382ce367d6",
            "cd3da667408540d083660bc5cb7877f7",
            "dbcd8399f6d8441baa893e7ab63b20c6",
            "ac90563888914c15a4199e227d7d5946",
            "bd35002be6ff49e0b57d5baf64c1f047",
            "aa6a3476a30e4cabb106b24adfb30539",
            "f38097ea5f064d9d83a904e103acf600",
            "eb4c8cb69b3041a98e8c8c161cee6e88",
            "fb147978277f4d16be4318920afec78a",
            "0a73a163076b442da7b111830fa861b2",
            "ac476e2b5a3d441ba3426c532b9d3b4a",
            "469ea131985740e89f64c2ecc963ca15",
            "6597f2aeb12f47f1bf6770c8d41f9367",
            "f41b7017fcf14f1692e684c76bf92c80",
            "6af372d0cdad4aa4a7fe38085b8a17db",
            "03d0249e1db44bdcac96163160b43c32",
            "4ab0c0b954ff4f78af1d7358a4445892",
            "fd1032bdc1c1466cb6d7162888bf01c0",
            "4e5cfb425dea49e2aa5228d700b189ae",
            "4a92dbb982ec4ee1bf0baca7a913d88a"
          ]
        },
        "id": "0OLtg42euQEk",
        "outputId": "224854c2-8dc2-4868-dd50-6819dbe89487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GET DATA - START \n",
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/my_fire_smoke_dataset/1.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41b519065c7345558280f3fdfd32782c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a73a163076b442da7b111830fa861b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bounding_box: {'class': 'Fire', 'x': 0.4852941176470588, 'y': 0.25416666666666665, 'width': 0.8823529411764706, 'height': 0.45833333333333337}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.4852941176470588, 'y': 0.25416666666666665, 'width': 0.8823529411764706, 'height': 0.45833333333333337}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.41150000000000003, 'y': 0.33066666666666666, 'width': 0.8130000000000001, 'height': 0.6453333333333333}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.41150000000000003, 'y': 0.33066666666666666, 'width': 0.8130000000000001, 'height': 0.6453333333333333}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.5024509803921569, 'y': 0.2, 'width': 0.8970588235294118, 'height': 0.35000000000000003}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.5024509803921569, 'y': 0.2, 'width': 0.8970588235294118, 'height': 0.35000000000000003}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.3802931596091205, 'y': 0.2305194805194805, 'width': 0.7312703583061889, 'height': 0.43073593073593075}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.3802931596091205, 'y': 0.2305194805194805, 'width': 0.7312703583061889, 'height': 0.43073593073593075}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.546875, 'y': 0.4847222222222222, 'width': 0.246875, 'height': 0.25277777777777777}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.546875, 'y': 0.4847222222222222, 'width': 0.246875, 'height': 0.25277777777777777}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.46718750000000003, 'y': 0.49444444444444446, 'width': 0.15937500000000002, 'height': 0.19444444444444445}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.46718750000000003, 'y': 0.49444444444444446, 'width': 0.15937500000000002, 'height': 0.19444444444444445}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.45625000000000004, 'y': 0.5458333333333334, 'width': 0.096875, 'height': 0.13611111111111113}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.45625000000000004, 'y': 0.5458333333333334, 'width': 0.096875, 'height': 0.13611111111111113}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.6078125000000001, 'y': 0.3875, 'width': 0.371875, 'height': 0.2638888888888889}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.6078125000000001, 'y': 0.3875, 'width': 0.371875, 'height': 0.2638888888888889}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.51484375, 'y': 0.4236111111111111, 'width': 0.18906250000000002, 'height': 0.23611111111111113}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.51484375, 'y': 0.4236111111111111, 'width': 0.18906250000000002, 'height': 0.23611111111111113}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.7254901960784313, 'y': 0.3, 'width': 0.5, 'height': 0.3277777777777778}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.7254901960784313, 'y': 0.3, 'width': 0.5, 'height': 0.3277777777777778}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.517156862745098, 'y': 0.24027777777777778, 'width': 0.6225490196078431, 'height': 0.45833333333333337}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.517156862745098, 'y': 0.24027777777777778, 'width': 0.6225490196078431, 'height': 0.45833333333333337}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.49921875000000004, 'y': 0.8402777777777778, 'width': 0.22031250000000002, 'height': 0.275}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.49921875000000004, 'y': 0.8402777777777778, 'width': 0.22031250000000002, 'height': 0.275}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.478125, 'y': 0.5777777777777778, 'width': 0.16562500000000002, 'height': 0.18888888888888888}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.478125, 'y': 0.5777777777777778, 'width': 0.16562500000000002, 'height': 0.18888888888888888}\n",
            "bounding_box: {'class': 'Smoke', 'x': 0.5800000000000001, 'y': 0.5595238095238095, 'width': 0.04, 'height': 0.13095238095238093}\n",
            "_generate_examples(), DATA: {'class': 'Smoke', 'x': 0.5800000000000001, 'y': 0.5595238095238095, 'width': 0.04, 'height': 0.13095238095238093}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.44140625, 'y': 0.3236111111111111, 'width': 0.2015625, 'height': 0.2638888888888889}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.44140625, 'y': 0.3236111111111111, 'width': 0.2015625, 'height': 0.2638888888888889}\n",
            "bounding_box: {'class': 'Fire', 'x': 0.28515625, 'y': 0.4361111111111111, 'width': 0.5171875, 'height': 0.35000000000000003}\n",
            "_generate_examples(), DATA: {'class': 'Fire', 'x': 0.28515625, 'y': 0.4361111111111111, 'width': 0.5171875, 'height': 0.35000000000000003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference - Lets load & use the model**"
      ],
      "metadata": {
        "id": "Ql-FyOrKyUTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#INFERENCE - Lets use the mode\n",
        "#load previously built model from disk to avoid having to retrain everytime you want to use the model\n",
        "model_path = F\"/content/gdrive/My Drive/ece551/week2_model/YOLOV8_model.keras\"\n",
        "loaded_model = keras.saving.load_model(model_path)\n",
        "model = loaded_model\n",
        "if model is not None:\n",
        "    print(\"Model loaded from disk\")\n",
        "else:\n",
        "    print(\"Failed to load model from disk\")\n",
        "\n",
        "if model is not None:\n",
        "    model.prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
        "    bounding_box_format=\"xyxy\",\n",
        "    from_logits=True,\n",
        "    iou_threshold=0.5,\n",
        "    confidence_threshold=0.75,\n",
        ")\n",
        "\n",
        "#LOAD MODEL - END\n",
        "#INFERENCE\n",
        "visualization_ds = eval_ds.unbatch()\n",
        "visualization_ds = visualization_ds.ragged_batch(16)\n",
        "images, y_true = next(iter(visualization_ds.take(1)))\n",
        "y_pred = model.predict(images)\n",
        "\n",
        "#VISUALIZE PREDICTION\n",
        "print(\"VISUALIZE PREDICTION - START\")\n",
        "visualize_predictions(images, y_true, y_pred,bounding_box_format=\"xyxy\")\n",
        "print(\"VISUALIZE PREDICTION - END\")\n",
        "\n",
        "model.prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
        "    bounding_box_format=\"xyxy\",\n",
        "    from_logits=True,\n",
        "    iou_threshold=0.5,\n",
        "    confidence_threshold=0.75,\n",
        ")\n",
        "\n",
        "#visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xyxy\")\n",
        "\n",
        "#METRICS CALL BACK\n",
        "print(metrics_callback.model.summary())"
      ],
      "metadata": {
        "id": "jfLfbRIDzIyg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "b860dbae-c9c6-4113-ef68-bfe9250b8bde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/task.py:43: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
            "/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/task.py:43: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from disk\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'eval_ds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-37bd56ebeb0f>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#LOAD MODEL - END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#INFERENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mvisualization_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mvisualization_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualization_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualization_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_ds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This is work in progress.**\n",
        "\n",
        "**There are known issues with Keras's implementation:**\n",
        "\n",
        "1) https://github.com/keras-team/keras-cv/issues/2095\n",
        "\n",
        "Wideli expected metrics are not being reported back.\n",
        "\n",
        "KERAS YOLOv8 DOEST traditional metrics: https://github.com/keras-team/keras/issues/19416\n",
        "\n",
        "2) https://github.com/keras-team/keras-cv/issues/2442\n",
        "\n",
        "Bad performance when compared to Ultralytics. This is probably due to problem #1 as we have no standard metrics.\n",
        "\n",
        "3) Furthermore, we should try freezing the layers and comparing the performnance when issues #1 & #2 are fixed by Keras."
      ],
      "metadata": {
        "id": "VDXpTDnlPDoo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOUnxtk+qfRGbd5hksERIw5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41b519065c7345558280f3fdfd32782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55d70f4294c144698fbedb58eb55f741",
              "IPY_MODEL_786588327cce41bd8781e5382ce367d6",
              "IPY_MODEL_cd3da667408540d083660bc5cb7877f7"
            ],
            "layout": "IPY_MODEL_dbcd8399f6d8441baa893e7ab63b20c6"
          }
        },
        "55d70f4294c144698fbedb58eb55f741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac90563888914c15a4199e227d7d5946",
            "placeholder": "​",
            "style": "IPY_MODEL_bd35002be6ff49e0b57d5baf64c1f047",
            "value": "Generating splits...:   0%"
          }
        },
        "786588327cce41bd8781e5382ce367d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6a3476a30e4cabb106b24adfb30539",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f38097ea5f064d9d83a904e103acf600",
            "value": 0
          }
        },
        "cd3da667408540d083660bc5cb7877f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4c8cb69b3041a98e8c8c161cee6e88",
            "placeholder": "​",
            "style": "IPY_MODEL_fb147978277f4d16be4318920afec78a",
            "value": " 0/2 [00:00&lt;?, ? splits/s]"
          }
        },
        "dbcd8399f6d8441baa893e7ab63b20c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac90563888914c15a4199e227d7d5946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd35002be6ff49e0b57d5baf64c1f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa6a3476a30e4cabb106b24adfb30539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38097ea5f064d9d83a904e103acf600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb4c8cb69b3041a98e8c8c161cee6e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb147978277f4d16be4318920afec78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a73a163076b442da7b111830fa861b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac476e2b5a3d441ba3426c532b9d3b4a",
              "IPY_MODEL_469ea131985740e89f64c2ecc963ca15",
              "IPY_MODEL_6597f2aeb12f47f1bf6770c8d41f9367"
            ],
            "layout": "IPY_MODEL_f41b7017fcf14f1692e684c76bf92c80"
          }
        },
        "ac476e2b5a3d441ba3426c532b9d3b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af372d0cdad4aa4a7fe38085b8a17db",
            "placeholder": "​",
            "style": "IPY_MODEL_03d0249e1db44bdcac96163160b43c32",
            "value": "Generating train examples...: "
          }
        },
        "469ea131985740e89f64c2ecc963ca15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab0c0b954ff4f78af1d7358a4445892",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd1032bdc1c1466cb6d7162888bf01c0",
            "value": 1
          }
        },
        "6597f2aeb12f47f1bf6770c8d41f9367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5cfb425dea49e2aa5228d700b189ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4a92dbb982ec4ee1bf0baca7a913d88a",
            "value": " 16/? [03:22&lt;00:00,  1.64s/ examples]"
          }
        },
        "f41b7017fcf14f1692e684c76bf92c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af372d0cdad4aa4a7fe38085b8a17db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d0249e1db44bdcac96163160b43c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab0c0b954ff4f78af1d7358a4445892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fd1032bdc1c1466cb6d7162888bf01c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e5cfb425dea49e2aa5228d700b189ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a92dbb982ec4ee1bf0baca7a913d88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}